from fastapi import HTTPException, Depends
from fastapi.responses import JSONResponse
from sqlalchemy.orm import Session
from langchain.memory import ConversationBufferMemory
from langchain_ollama import OllamaLLM, OllamaEmbeddings
from pydantic import BaseModel
import logging
import uuid
from typing import List, Dict, Optional, Tuple
from datetime import datetime
from dateutil.parser import parse

from database import get_db, ChatMessage
from qdrant_db import qdrant_client, collection_name

logger = logging.getLogger(__name__)
llm = OllamaLLM(model="llama3.2")
embed_model = OllamaEmbeddings(model="llama3.2")
ai_memories = {}

CATEGORIES = [
    "–ù–∞—É–∫–∞ –∏ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏",
    "–ë–∏–∑–Ω–µ—Å –∏ —Ñ–∏–Ω–∞–Ω—Å—ã",
    "–û–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ",
    "–ó–¥–æ—Ä–æ–≤—å–µ",
    "–ì–æ—Å—É–¥–∞—Ä—Å—Ç–≤–æ –∏ –ø—Ä–∞–≤–æ",
    "–¢–≤–æ—Ä—á–µ—Å—Ç–≤–æ",
    "–†–∞–∑–Ω–æ–µ"
]


class ChatRequest(BaseModel):
    session_id: str
    message: str
    filters: Optional[dict] = None


class SearchFilters(BaseModel):
    category: Optional[str] = None
    date_from: Optional[str] = None
    date_to: Optional[str] = None


def extract_search_params(text: str) -> Tuple[Optional[str], Optional[Dict[str, str]]]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏—é –∏ –¥–∞—Ç—ã –∏–∑ —Ç–µ–∫—Å—Ç–∞ –∑–∞–ø—Ä–æ—Å–∞"""
    prompt = f"""
    –û–ø—Ä–µ–¥–µ–ª–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏—é –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏–∑ —Å–ø–∏—Å–∫–∞: {CATEGORIES}
    –ï—Å–ª–∏ –≤ —Ç–µ–∫—Å—Ç–µ —É–∫–∞–∑–∞–Ω –ø–µ—Ä–∏–æ–¥, –æ–ø—Ä–µ–¥–µ–ª–∏ –¥–∞—Ç—ã –≤ —Ñ–æ—Ä–º–∞—Ç–µ YYYY-MM-DD.
    –§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ JSON: {{"category": "...", "dates": {{"start": "...", "end": "..."}}}}
    –¢–µ–∫—Å—Ç: "{text[:500]}"
    """
    try:
        response = llm.invoke(prompt)
        result = eval(response)

        category = result.get("category") if result.get("category") in CATEGORIES else None

        dates = None
        if result.get("dates"):
            dates = {
                "start": parse(result["dates"]["start"]).strftime('%Y-%m-%d') if result["dates"].get("start") else None,
                "end": parse(result["dates"]["end"]).strftime('%Y-%m-%d') if result["dates"].get("end") else None
            }

        return category, dates
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∑–∞–ø—Ä–æ—Å–∞: {e}")
        return None, None


async def search_in_qdrant(
        query: str,
        category: Optional[str] = None,
        upload_dates: Optional[Dict[str, str]] = None,
        limit: int = 15
) -> List[Dict]:
    """–ü–æ–∏—Å–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π"""
    from qdrant_client.models import Filter, FieldCondition, MatchValue, Range

    must_conditions = []

    if category:
        must_conditions.append(FieldCondition(
            key="category",
            match=MatchValue(value=category)
        ))

    if upload_dates:
        date_conditions = []
        if upload_dates.get("start"):
            date_conditions.append(Range(gte=upload_dates["start"]))
        if upload_dates.get("end"):
            date_conditions.append(Range(lte=upload_dates["end"]))

        if date_conditions:
            must_conditions.append(FieldCondition(
                key="upload_date",
                range=Range(**{
                    k: v for cond in date_conditions
                    for k, v in cond.dict().items()
                })
            ))

    query_embedding = embed_model.embed_query(query)

    search_results = qdrant_client.search(
        collection_name=collection_name,
        query_vector=query_embedding,
        query_filter=Filter(must=must_conditions) if must_conditions else None,
        limit=limit,
        with_payload=True
    )

    return [{
        "text": hit.payload["text"],
        "source": hit.payload.get("source", "unknown"),
        "upload_date": hit.payload.get("upload_date"),
        "category": hit.payload.get("category"),
        "score": hit.score
    } for hit in search_results]


async def generate_rag_response(
        query: str,
        context: List[Dict],
        category: Optional[str] = None,
        upload_dates: Optional[Dict[str, str]] = None
) -> str:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —Å —É—á–µ—Ç–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
    context_str = "\n\n".join([
        f"üîπ –ò—Å—Ç–æ—á–Ω–∏–∫: {item['source']}\n"
        f"–î–∞—Ç–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {item.get('upload_date', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}\n"
        f"–ö–∞—Ç–µ–≥–æ—Ä–∏—è: {item.get('category', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}\n"
        f"–ö–æ–Ω—Ç–µ–Ω—Ç: {item['text'][:300]}..."
        for item in context
    ])

    filters_info = []
    if category:
        filters_info.append(f"–ö–∞—Ç–µ–≥–æ—Ä–∏—è: {category}")
    if upload_dates:
        start = upload_dates.get('start', '–ª—é–±–∞—è')
        end = upload_dates.get('end', '–ª—é–±–∞—è')
        filters_info.append(f"–ü–µ—Ä–∏–æ–¥ –∑–∞–≥—Ä—É–∑–∫–∏: {start} ‚Äî {end}")

    prompt = f"""
    –û—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å, –∏—Å–ø–æ–ª—å–∑—É—è —Ç–æ–ª—å–∫–æ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ.
    {f"–§–∏–ª—å—Ç—Ä—ã –ø–æ–∏—Å–∫–∞: {', '.join(filters_info)}" if filters_info else ""}

    –î–∞–Ω–Ω—ã–µ:
    {context_str if context else "–ù–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"}

    –í–æ–ø—Ä–æ—Å: {query}

    –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –æ—Ç–≤–µ—Ç—É:
    1. –ë—É–¥—å —Ç–æ—á–Ω—ã–º –∏ –ª–∞–∫–æ–Ω–∏—á–Ω—ã–º
    2. –£–∫–∞–∂–∏ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ [1] filename.pdf
    3. –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ ‚Äî —Å–æ–æ–±—â–∏ –æ–± —ç—Ç–æ–º
    """
    return llm.invoke(prompt).strip()


async def chat_endpoint(request: ChatRequest, db: Session = Depends(get_db)):
    session_id = request.session_id
    user_message = request.message.strip()

    if not user_message or len(user_message) < 3:
        raise HTTPException(status_code=400, detail="–°–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π –∑–∞–ø—Ä–æ—Å")

    db.add(ChatMessage(session_id=session_id, role="user", message=user_message))
    db.commit()

    if session_id not in ai_memories:
        ai_memories[session_id] = ConversationBufferMemory(memory_key="history", return_messages=True)
    memory = ai_memories[session_id]

    try:
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∏–ª—å—Ç—Ä–æ–≤
        filters = request.filters or {}
        category = filters.get("category")
        upload_dates = None

        if filters.get("date_from") or filters.get("date_to"):
            upload_dates = {
                "start": filters.get("date_from"),
                "end": filters.get("date_to")
            }

        refined_query = condense_question(user_message, memory)

        # –ï—Å–ª–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏—è –Ω–µ —É–∫–∞–∑–∞–Ω–∞ –≤ —Ñ–∏–ª—å—Ç—Ä–∞—Ö, –æ–ø—Ä–µ–¥–µ–ª—è–µ–º –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
        if not category:
            category, _ = extract_search_params(refined_query)

        keywords = generate_search_keywords(refined_query, category)

        logger.info(f"–ü–æ–∏—Å–∫: '{refined_query}' | –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {category} | –î–∞—Ç—ã: {upload_dates}")

        search_results = await search_in_qdrant(
            query=keywords,
            category=category,
            upload_dates=upload_dates,
            limit=15
        )

        ai_response = await generate_rag_response(
            query=user_message,
            context=search_results,
            category=category,
            upload_dates=upload_dates
        )

        if len(ai_response) > 10000:
            ai_response = ai_response[:10000] + "\n\n[–û—Ç–≤–µ—Ç —Å–æ–∫—Ä–∞—â–µ–Ω]"

        metadata = {
            "category": category,
            "upload_dates": upload_dates,
            "sources": list(set(res['source'] for res in search_results))
        }

        db.add(ChatMessage(session_id=session_id, role="ai", message=ai_response))
        db.commit()
        memory.save_context({"input": user_message}, {"output": ai_response})

        return JSONResponse(content={
            "response": ai_response,
            "metadata": metadata
        })

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞: {e}")
        raise HTTPException(status_code=500, detail="–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞")


async def get_chat_history(session_id: str, db: Session = Depends(get_db)):
    history = db.query(ChatMessage).filter(ChatMessage.session_id == session_id).all()
    return [{"role": msg.role, "message": msg.message} for msg in history]


async def clear_chat_history(session_id: str, db: Session = Depends(get_db)):
    db.query(ChatMessage).filter(ChatMessage.session_id == session_id).delete()
    db.commit()
    ai_memories.pop(session_id, None)
    return JSONResponse(content={"message": "–ò—Å—Ç–æ—Ä–∏—è —á–∞—Ç–∞ –æ—á–∏—â–µ–Ω–∞"})


async def create_new_chat():
    new_session_id = str(uuid.uuid4())
    return JSONResponse(content={"session_id": new_session_id})


def generate_search_keywords(question: str, category: Optional[str] = None) -> str:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å —É—á–µ—Ç–æ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∏"""
    prompt = f"""
    –ò–∑–≤–ª–µ–∫–∏ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏–∑ –≤–æ–ø—Ä–æ—Å–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö. 
    {"–£—á—Ç–∏, —á—Ç–æ –¥–æ–∫—É–º–µ–Ω—Ç—ã –æ—Ç–Ω–æ—Å—è—Ç—Å—è –∫ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏: " + category + "." if category else ""}
    –§–æ—Ä–º–∞—Ç: —Å–ª–æ–≤–∞ —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é, –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.

    –í–æ–ø—Ä–æ—Å: "{question}"

    –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞:
    """
    return llm.invoke(prompt).strip()


def condense_question(user_message: str, memory: ConversationBufferMemory) -> str:
    """–£—Ç–æ—á–Ω—è–µ—Ç –∏ —É–ª—É—á—à–∞–µ—Ç —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫—É –≤–æ–ø—Ä–æ—Å–∞"""
    history = memory.load_memory_variables({}).get("history", "")
    prompt = f"""
    –£–ª—É—á—à–∏ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫—É –≤–æ–ø—Ä–æ—Å–∞ –¥–ª—è –±–æ–ª–µ–µ —Ç–æ—á–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞. –°–æ—Ö—Ä–∞–Ω–∏ –∏—Å—Ö–æ–¥–Ω—ã–π —Å–º—ã—Å–ª.

    –ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞:
    {history}

    –ò—Å—Ö–æ–¥–Ω—ã–π –≤–æ–ø—Ä–æ—Å:
    "{user_message}"

    –£–ª—É—á—à–µ–Ω–Ω—ã–π –≤–æ–ø—Ä–æ—Å:
    """
    return llm.invoke(prompt).strip()